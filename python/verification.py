
#ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
import torch

from torchvision import datasets, transforms
from torch.utils.data import DataLoader, Subset
#datasets : MNIST ê°™ì€ ë°ì´í„° ì…‹ì„ ì‰½ê²Œ ê°€ì ¸ì˜¤ê¸° ìœ„í•¨
#transforms : ì´ë¯¸ì§€ ì „ì²˜ë¦¬ë¥¼ ìœ„í•œë„êµ¬

from PIL import Image

from torch.utils.data import DataLoader
#DataLoader : ë°ì´í„°ë¥¼ batch ë‹¨ìœ„ë¡œ ë‚˜ëˆ ì„œ ì²˜ë¦¬(ë©”ëª¨ë¦¬ ì ˆì•½ + ë¹ ë¦„)
from PIL import ImageOps



# ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ í…ì„œë¡œ ë³€í™˜
from torchvision.datasets import EMNIST

transform = transforms.Compose([
transforms.Lambda(lambda img: ImageOps.invert(img)),              # ìƒ‰ ë°˜ì „
    transforms.Lambda(lambda img: ImageOps.mirror(img)),          # ì¢Œìš° ëŒ€ì¹­ ë³µì›
    transforms.Lambda(lambda img: img.rotate(90, expand=True)),   # ì‹œê³„ë°©í–¥ 90ë„ íšŒì „
    transforms.ToTensor()
])


target_labels = [1, 2, 3]
def filter_dataset(dataset):
    indices = [i for i, (_, label) in enumerate(dataset) if label in target_labels]
    filtered = Subset(dataset, indices)
    return filtered

# ì›ë³¸ ì „ì²´ EMNIST ë°ì´í„°ì…‹
full_train_dataset = EMNIST(root='./data', split='letters', train=True, download=True, transform=transform)
full_test_dataset = EMNIST(root='./data', split='letters', train=False, download=True, transform=transform)

# 'a', 'b', 'c'ë§Œ í•„í„°ë§
train_dataset = filter_dataset(full_train_dataset)
test_dataset = filter_dataset(full_test_dataset)

# Subsetì€ ë‚´ë¶€ì— indexë§Œ ë“¤ê³  ìˆì–´ì„œ custom Dataset ê°ì‹¸ì¤˜ì•¼ í•¨
class ABCDataset(torch.utils.data.Dataset):
    def __init__(self, subset):
        self.subset = subset

    def __len__(self):
        return len(self.subset)

    def __getitem__(self, idx):
        img, label = self.subset[idx]
        return img, torch.tensor(label - 1, dtype=torch.long)

# âœ… ë¬¸ì œ í•µì‹¬ ìš”ì•½
# PyTorchì˜ CrossEntropyLossëŠ” **ë¼ë²¨(label)**ì´ ë°˜ë“œì‹œ
# torch.LongTensor íƒ€ì…ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
#
# í•˜ì§€ë§Œ í˜„ì¬ ABCDatasetì˜ __getitem__()ì€ label - 1ë§Œ ìˆ˜í–‰í•˜ê³ ,
# ìë£Œí˜•(int, float)ì€ torch.Tensorì¸ì§€ í™•ì‹¤ì¹˜ ì•ŠìŠµë‹ˆë‹¤.


train_dataset = ABCDataset(train_dataset)
test_dataset = ABCDataset(test_dataset)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)
#======================================================================================#

#1. CNN ëª¨ë¸ ë§Œë“¤ê¸°

import torch.nn as nn
import torch.nn.functional as F

class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()

        #pixel ë°ì´í„° ì¶”ê°€
        self.conv1 = nn.Conv2d(1, 3, kernel_size=5, padding=0, bias=True)
        #í•©ì„±ê³± ë ˆì´ì–´

        self.pool = nn.MaxPool2d(2, 2)  # 2x2 Max pooling
        #MaxPool2d(2, 2): 2x2 ìµœëŒ€ í’€ë§ â†’ í¬ê¸°ë¥¼ ì ˆë°˜ìœ¼ë¡œ ì¤„ì„


        self.conv2 = nn.Conv2d(3, 3, kernel_size=5, padding=0, bias=True)

        self.fc1 = nn.Linear(3 * 4 * 4, 3, bias=True)  # ì™„ì „ì—°ê²°,  # a,b,c ë¶„ë¥˜
        # self.fc2 = nn.Linear(32, 3)  # a,b,c ë¶„ë¥˜

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        # x = x.view(-1, 3 * 4 * 4)  # Flatten
        x = x.view(x.size(0), -1)
        ##soft maxí•œê±°
        x = self.fc1(x)

        return x

model = CNN()

import numpy as np
import matplotlib.pyplot as plt

# .mem ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
values = [int(line.strip(), 16) for line in open("./mem_outputs/b_4.mem") if line.strip().startswith("0x")]
img_array = np.array(values, dtype=np.uint8).reshape(28, 28)

plt.imshow(img_array, cmap='gray')  # ë°ì„ìˆ˜ë¡ í°ìƒ‰
plt.title("Loaded .mem Image")
plt.axis('off')
plt.show()
# Conv1 weights and bias
model.conv1.weight.data = torch.tensor([
    [[[12,13,33,20,42],[11,24,54,33,28],[45,51,19,8,22],[-14,14,-22,-20,-8],[-37,-21,-22,-42,-50]]],
    [[[23,21,-11,25,26],[27,4,16,-1,26],[2,20,-3,9,61],[44,8,35,31,15],[34,47,43,31,46]]],
    [[[1,0,-4,39,23],[0,9,33,47,51],[4,-15,20,41,-1],[-49,-37,17,-16,-7],[-52,-16,-48,-32,-19]]]
], dtype=torch.float32)
model.conv1.bias.data = torch.tensor([25, -41, 43], dtype=torch.float32)


model.conv2.weight.data = torch.tensor([
    [   # Output Channel 0
       [[ 33,    9,    9, - 7 ,    0],
        [29,   22, - 13,   26,    34],
        [15,    5,   26,   38,    46],
        [19,   27,   31,   37,    33],
       [ - 2,   11,    8, - 5 , - 3]],

        [[14,   16,   14,   18,   34],
        [15, - 5 ,  15 ,  26 ,  15],
        [- 31,   13, - 1,    1,   17],
        [- 19, - 9 ,- 24, - 15, - 2],
        [- 29, - 31, - 5, - 22, - 18]],

       [[ 4 ,- 17 ,   4 ,- 8   ,- 7],
       [ 35, - 28, - 36, - 16 ,  25],
       [ 30,   27,   14,   39 ,  44],
       [ 47,   41,   45,   37 ,  31],
       [ 46,   52,   28, - 4, - 5]],
    ],

    [   # Output Channel 1
        [[ -16,  -29,  - 37, - 6 ,- 24],
        [- 27, - 27,  - 2 ,   4 ,   5],
        [- 9 , - 4 , - 1  , - 7 ,  17],
       [  11 ,   7 , - 20 ,- 6  ,  4],
       [  25 ,   7 ,   15 ,- 5  , 16]],

        [[-1 ,- 30, - 10,   22,   10],
        [13 ,  11,  - 6,    1,   38],
        [34 ,  12,    6,    7,   30],
        [33 ,  26,   30,    9,   23],
        [51 ,  25,   29,   16,    9]],

        [[-28 ,   6 , - 8 ,- 20, - 53],
       [ - 34, - 20,   3 ,- 4 ,- 47],
       [ - 45, - 40, - 8 ,  6 ,   5],
       [ - 66, - 56, -52 ,-35 ,- 28],
       [ - 41, - 45, -41 ,-47 ,- 11]],
    ],

    [   # Output Channel 2
       [[ -9,    5,    8 ,  13 ,- 10],
       [ - 8, - 16, - 2  , 10  ,  3],
       [ - 4,   11,    3 ,- 12 ,  7],
       [   1, - 13,    1 ,   1 ,- 1],
        [-10, - 14,  - 15,    0, - 6]],

       [[  11 ,  11 ,- 7, - 13 ,   4],
        [- 15 ,   6 ,- 15 ,- 9 ,   6],
        [- 9  , - 8 ,   0 ,- 1 ,- 10],
        [- 9  ,   3 ,   1 ,   2, - 9],
        [- 2  , - 4 , - 3 ,   2, -15]],

       [[ 5  ,  2 ,   3, - 15, - 9],
      [ -13 ,   2,   2, - 7 ,- 9],
       [ 1  ,  7 , - 4, - 1 ,- 15],
        [10 ,- 3 ,  11, - 13,   10],
       [ -7 ,   1,   9, - 12, - 5]],
    ]
], dtype=torch.float32)

# biasë„ ë„£ê³  ì‹¶ë‹¤ë©´ ì˜ˆì‹œ:
model.conv2.bias.data = torch.tensor([2, -23, 1], dtype=torch.float32)  # ë˜ëŠ” ì •ìˆ˜ bias

model.fc1.weight.data = torch.tensor([
    [5, -11, -15, 26, 31, 3, -18, 1, 28, -16, -20, 5, 15, -18, -32, 3, 1, -10, 10, 6, 1, 20, -19, -12, -18, 3, -10, -27, 37, 11, 27, -12, 13, -2, -4, 5, -14, 13, -15, -6, 2, 2, -14, -17, 5, -6, 5, 12],
    [-20, 17, 26, 2, -11, -10, 24, 23, 0, -25, 5, -18, 9, 9, 15, -17, 11, 3, 15, -2, 20, -17, -15, 0, 27, 3, -24, 7, -21, -12, -19, -22, 8, 17, -12, 8, -15, 6, 3, 5, 9, 5, -11, 13, -5, -14, 5, -14],
    [20, -3, -14, -10, -20, -8, -10, -18, -7, 21, 17, 13, -24, -18, -10, 5, 0, -3, 11, -1, -33, 13, 29, 22, -3, 1, 16, 23, -5, -18, 11, -14, 6, -3, -12, 7, -8, -2, 3, -13, 15, 2, -6, -14, -10, -17, -5, 16],
], dtype=torch.float32)

model.fc1.bias.data = torch.tensor([11, -7, -15], dtype=torch.float32)  # ë˜ëŠ” ì •ìˆ˜ bias

# 3. Conv1 ì—°ì‚° ê²°ê³¼ ë³´ê¸°
import torch
import torch.nn.functional as F
import numpy as np

# âœ… ì…ë ¥: 28x28 ì´ë¯¸ì§€, ëª¨ë“  ê°’ì´ 1
# âœ… 0~255ê¹Œì§€ ë°˜ë³µë˜ëŠ” 28x28 input feature map ìƒì„±
def create_cyclic_input(height=28, width=28):
    """
    0ë¶€í„° 255ê¹Œì§€ ê°’ì´ ë°˜ë³µë˜ëŠ” feature map ìƒì„±
    28x28 = 784ê°œ í”½ì…€ì´ë¯€ë¡œ, 784 Ã· 256 = 3ë²ˆ ì™„ì „ ë°˜ë³µ + ë‚˜ë¨¸ì§€ 16ê°œ
    """
    total_pixels = height * width  # 784

    # 0~255 íŒ¨í„´ì„ í•„ìš”í•œ ë§Œí¼ ë°˜ë³µ
    values = []
    for i in range(total_pixels):
        values.append(1)  # 0, 1, 2, ..., 255, 0, 1, 2, ...

    # numpy ë°°ì—´ë¡œ ë³€í™˜ í›„ 28x28ë¡œ reshape
    input_array = np.array(values, dtype=np.float32).reshape(height, width)

    # PyTorch tensorë¡œ ë³€í™˜ (batch_size=1, channels=1 ì°¨ì› ì¶”ê°€)
    input_tensor = torch.from_numpy(input_array).unsqueeze(0).unsqueeze(0)
    # shape: [1, 1, 28, 28]

    return input_tensor


import re


def load_mem_file_to_tensor(mem_file_path, height=28, width=28):
    """
    .mem íŒŒì¼ì„ ì½ì–´ì„œ PyTorch tensorë¡œ ë³€í™˜
    """
    values = []

    with open(mem_file_path, 'r') as f:
        lines = f.readlines()

    for line in lines:
        line = line.strip()
        if not line or line.startswith('//'):
            continue

        # 16ì§„ìˆ˜ ê°’ ì¶”ì¶œ (0xí˜•ì‹)
        hex_match = re.search(r'0x([0-9A-Fa-f]+)', line)
        if hex_match:
            hex_value = hex_match.group(1)
            decimal_value = int(hex_value, 16)
            values.append(decimal_value)

    # numpy ë°°ì—´ë¡œ ë³€í™˜ í›„ reshape
    input_array = np.array(values, dtype=np.float32).reshape(height, width)

    # PyTorch tensorë¡œ ë³€í™˜ (batch_size=1, channels=1 ì°¨ì› ì¶”ê°€)
    input_tensor = torch.from_numpy(input_array).unsqueeze(0).unsqueeze(0)

    return input_tensor

# âœ… ìƒˆë¡œìš´ input tensor ìƒì„±
# input_tensor = create_cyclic_input(28, 28)
input_tensor = load_mem_file_to_tensor('../PythonProject2/mem_outputs/b_4.mem', 28, 28)

print("ğŸ”¹ ìƒˆë¡œìš´ Input Feature Map ì •ë³´:")
print(f"Shape: {input_tensor.shape}")
print(f"Min value: {input_tensor.min().item()}")
print(f"Max value: {input_tensor.max().item()}")

# âœ… ì´ì œ ì´ input_tensorë¡œ CNN ì—°ì‚° ìˆ˜í–‰
print("\n" + "=" * 80)
print("ğŸ”¹ ìƒˆë¡œìš´ Inputìœ¼ë¡œ CNN ì—°ì‚° ì‹œì‘")
print("=" * 80)

# âœ… Conv1 ì—°ì‚° - ì „ì²´ ìœ„ì¹˜ì— ëŒ€í•œ ìƒì„¸ ê³„ì‚°
print("\n" + "=" * 80)
print("ğŸ”¹ ìƒˆë¡œìš´ Inputìœ¼ë¡œ CNN ì—°ì‚° ì‹œì‘ - ì „ì²´ ìœ„ì¹˜ ìƒì„¸ ê³„ì‚°")
print("=" * 80)

# input_tensorê°€ ì •ì˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •
input_feature = input_tensor[0]  # shape: [3, 12, 12]
weight = model.conv1.weight.data  # weight shape í™•ì¸
bias = model.conv1.bias.data

# weight í…ì„œì˜ ì‹¤ì œ shape ì¶œë ¥
print(f"ğŸ” Weight shape: {weight.shape}")
print(f"ğŸ” Input feature shape: {input_feature.shape}")
print(f"ğŸ” Bias shape: {bias.shape}")

# weight shapeì— ë”°ë¼ input channel ìˆ˜ ê²°ì •
num_input_channels = weight.shape[1]  # weightì˜ ë‘ ë²ˆì§¸ ì°¨ì›ì´ input channel ìˆ˜
num_output_channels = weight.shape[0]  # weightì˜ ì²« ë²ˆì§¸ ì°¨ì›ì´ output channel ìˆ˜
kernel_h, kernel_w = weight.shape[2], weight.shape[3]

print(f"ğŸ” Input channels: {num_input_channels}, Output channels: {num_output_channels}")
print(f"ğŸ” Kernel size: {kernel_h}x{kernel_w}")

# ì¶œë ¥ í¬ê¸° ê³„ì‚° (padding=0, stride=1 ê°€ì •)
output_h = input_feature.shape[1] - kernel_h + 1
output_w = input_feature.shape[2] - kernel_w + 1
print(f"ğŸ” Output size: {output_h}x{output_w}")

# ì‹¤ì œ PyTorch conv1 ì—°ì‚° (ë¹„êµìš©)
conv1_out = model.conv1(input_tensor)
print(f"ğŸ” ì‹¤ì œ PyTorch ì¶œë ¥ shape: {conv1_out.shape}")

# ê° ì¶œë ¥ ì±„ë„ì— ëŒ€í•´ ê³„ì‚°
for output_channel in range(min(1, num_output_channels)):  # ì²« ë²ˆì§¸ ì±„ë„ë§Œ ìƒì„¸íˆ (ë„ˆë¬´ ë§ìœ¼ë©´ ì¡°ì •)
    print(f"\n" + "=" * 60)
    print(f"ğŸ¯ ì¶œë ¥ ì±„ë„ {output_channel} ìƒì„¸ ê³„ì‚°")
    print("=" * 60)

    # ê° ì¶œë ¥ ìœ„ì¹˜ì— ëŒ€í•´ ê³„ì‚°
    for output_y in range(output_h):
        for output_x in range(output_w):
            print(f"\n[ğŸ” ìœ„ì¹˜ ({output_y},{output_x}) ê³„ì‚°]")

            acc = 0
            channel_contributions = []  # ê° ì…ë ¥ ì±„ë„ì˜ ê¸°ì—¬ë„ ì €ì¥

            # ê° ì…ë ¥ ì±„ë„ì— ëŒ€í•´ ì»¨ë³¼ë£¨ì…˜ ê³„ì‚°
            for in_c in range(num_input_channels):
                kernel = weight[output_channel, in_c]  # kernel shape: [H, W]

                # input featureì˜ í•´ë‹¹ ì±„ë„ì—ì„œ íŒ¨ì¹˜ ì¶”ì¶œ
                if in_c < input_feature.shape[0]:  # input channelì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                    patch = input_feature[in_c, output_y:output_y + kernel_h, output_x:output_x + kernel_w]
                else:
                    print(f"âš ï¸ ì…ë ¥ ì±„ë„ {in_c}ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    continue

                mul = patch * kernel  # element-wise ê³±
                sum_mul = mul.sum().item()
                channel_contributions.append(sum_mul)

                print(f"  ğŸ“ ì…ë ¥ ì±„ë„ {in_c}: patchÃ—kernel í•©ê³„ = {sum_mul:.4f}")

                # ìƒì„¸ ì •ë³´ ì¶œë ¥ (ì„ íƒì ìœ¼ë¡œ - ë„ˆë¬´ ë§ìœ¼ë©´ ì£¼ì„ ì²˜ë¦¬)
                if output_y < 2 and output_x < 2:  # ì²˜ìŒ ëª‡ ê°œë§Œ ìƒì„¸íˆ
                    print(f"    ì…ë ¥ íŒ¨ì¹˜:\n{patch}")
                    print(f"    ì»¤ë„:\n{kernel}")
                    print(f"    ê³±:\n{mul}")

                acc += sum_mul

            # bias ë”í•˜ê¸° ì „ ê²°ê³¼ ìƒì„¸ ë¶„ì„
            print(f"\n  ğŸ§® ê° ì±„ë„ë³„ ê¸°ì—¬ë„:")
            for i, contrib in enumerate(channel_contributions):
                print(f"    ì±„ë„ {i}: {contrib:8.4f}")

            print(f"  ğŸ“Š ì „ì²´ ì±„ë„ í•©ê³„ (bias ì „): {acc:.4f}")
            print(f"  ğŸ¯ Bias ê°’: {bias[output_channel].item():.4f}")

            # bias ë”í•¨
            final_result = acc + bias[output_channel].item()

            # ê²°ê³¼ ë¹„êµ
            pytorch_result = conv1_out[0, output_channel, output_y, output_x].item()
            print(f"  âœ… ìµœì¢… ê²°ê³¼ (bias í›„): {final_result:.4f}")
            print(f"  ğŸ” PyTorch ê²°ê³¼: {pytorch_result:.4f}")
            print(f"  ğŸ“Š ì°¨ì´: {abs(final_result - pytorch_result):.6f}")

            # bias ì „í›„ ë¹„êµ
            print(f"  ğŸ“ˆ Bias íš¨ê³¼: {acc:.4f} â†’ {final_result:.4f} (ë³€í™”: {final_result - acc:+.4f})")

            if in_c < input_feature.shape[0]:  # input channelì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                patch = input_feature[in_c, output_y:output_y + kernel_h, output_x:output_x + kernel_w]
            else:
                print(f"âš ï¸ ì…ë ¥ ì±„ë„ {in_c}ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                continue

            mul = patch * kernel  # element-wise ê³±
            sum_mul = mul.sum().item()

            print(f"  ğŸ“ ì…ë ¥ ì±„ë„ {in_c}: patchÃ—kernel í•©ê³„ = {sum_mul:.1f}")

            # ìƒì„¸ ì •ë³´ ì¶œë ¥ (ì„ íƒì ìœ¼ë¡œ - ë„ˆë¬´ ë§ìœ¼ë©´ ì£¼ì„ ì²˜ë¦¬)
            if output_y < 2 and output_x < 2:  # ì²˜ìŒ ëª‡ ê°œë§Œ ìƒì„¸íˆ
                print(f"    ì…ë ¥ íŒ¨ì¹˜:\n{patch}")
                print(f"    ì»¤ë„:\n{kernel}")
                print(f"    ê³±:\n{mul}")

            acc += sum_mul

        # bias ë”í•¨
        acc += bias[output_channel].item()

        # ê²°ê³¼ ë¹„êµ
        pytorch_result = conv1_out[0, output_channel, output_y, output_x].item()
        print(f"  âœ… ê³„ì‚° ê²°ê³¼: {acc:.1f}")
        print(f"  ğŸ” PyTorch ê²°ê³¼: {pytorch_result:.1f}")
        print(f"  ğŸ“Š ì°¨ì´: {abs(acc - pytorch_result):.6f}")

print(f"\n" + "=" * 80)
print("ğŸ‰ ì „ì²´ ì»¨ë³¼ë£¨ì…˜ ì—°ì‚° ìƒì„¸ ê³„ì‚° ì™„ë£Œ!")
print("=" * 80)

print(f"â¡ï¸ ì‹¤ì œ conv1_out ê°’: {conv1_out[0, output_channel, output_y, output_x].item()}")
print("ğŸ”¹ [Conv1 ì¶œë ¥] shape:", conv1_out.shape)

# Conv1 ì¶œë ¥ì˜ ëª¨ë“  ìœ„ì¹˜ ê°’ ì¶œë ¥
print(f"\nğŸ”¹ Conv1 ì¶œë ¥ ìƒì„¸ (ëª¨ë“  ìœ„ì¹˜):")
print(f"ì¶œë ¥ shape: {conv1_out.shape}")

for channel in range(conv1_out.shape[1]):  # ê° ì¶œë ¥ ì±„ë„
    print(f"\nğŸ“ Conv1 ì±„ë„ {channel}:")
    channel_output = conv1_out[0, channel]  # [H, W]

    # ê° ìœ„ì¹˜ë³„ ê°’ ì¶œë ¥
    for y in range(channel_output.shape[0]):
        row_values = []
        for x in range(channel_output.shape[1]):
            row_values.append(f"{channel_output[y, x].item():8.1f}")
        print(f"  y={y}: [" + ", ".join(row_values) + "]")

# ê°„ë‹¨í•œ ìš”ì•½ë„ ì¶œë ¥
print(f"\nğŸ“Š Conv1 ì¶œë ¥ ìš”ì•½:")
for i in range(conv1_out.shape[1]):
    channel_data = conv1_out[0, i]
    print(
        f"ì±„ë„ {i}: min={channel_data.min().item():.1f}, max={channel_data.max().item():.1f}, mean={channel_data.mean().item():.1f}")
# âœ… ReLU ì ìš©
relu1_out = F.relu(conv1_out)
print("\n" + "=" * 60)
print("ğŸ”¹ [ReLU1 ì¶œë ¥] (Conv1 â†’ ReLU) - í–‰ë ¬ í˜•ì‹")
print("=" * 60)

for channel in range(relu1_out.shape[1]):
    print(f"\nğŸ”¹ ReLU1 ì±„ë„ {channel}:")
    channel_output = relu1_out[0, channel]  # [H, W]

    # í–‰ë ¬ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
    for y in range(channel_output.shape[0]):
        row_values = []
        for x in range(channel_output.shape[1]):
            row_values.append(f"{channel_output[y, x].item():8.1f}")
        print("  [" + ", ".join(row_values) + "]")


# âœ… MaxPooling1 ì ìš©
pool1_out = F.max_pool2d(relu1_out, 2, 2)
print("\nğŸ”¹ [MaxPool1 ì¶œë ¥] shape:", pool1_out.shape)
for i in range(pool1_out.shape[1]):
    print(f"MaxPool1 ì±„ë„ {i} ê°’:")
    print(pool1_out[0, i])

# âœ… MaxPool1ê³¼ Conv2 Weight ê³±ì…ˆ ìƒì„¸ ì¶œë ¥
print("\n" + "=" * 80)
print("ğŸ”¹ MaxPool1ê³¼ Conv2 Weight ê³±ì…ˆ ìƒì„¸ ê³¼ì •")
print("=" * 80)

# Conv2ì˜ weight shape: [out_channels, in_channels, kernel_height, kernel_width]
conv2_weight = model.conv2.weight.data  # shape: [3, 3, 5, 5]
conv2_bias = model.conv2.bias.data  # shape: [3]

# MaxPool1 ì¶œë ¥ shape: [1, 3, 12, 12]
pool1_data = pool1_out[0]  # batch dimension ì œê±° -> [3, 12, 12]

print(f"MaxPool1 ì¶œë ¥ shape: {pool1_data.shape}")
print(f"Conv2 weight shape: {conv2_weight.shape}")

# ì‹¤ì œ Conv2 ì—°ì‚° ê²°ê³¼
actual_conv2_out = model.conv2(pool1_out)
print("ì‹¤ì œ Conv2 ì¶œë ¥:")
for i in range(actual_conv2_out.shape[1]):
    print(f"ì±„ë„ {i}:")
    print(actual_conv2_out[0, i])

# âœ… Conv2 ì—°ì‚°
conv2_out = model.conv2(pool1_out)
print("\nğŸ”¹ [Conv2 ì¶œë ¥] shape:", conv2_out.shape)
for i in range(conv2_out.shape[1]):
    print(f"Conv2 ì±„ë„ {i} ê°’:")
    print(conv2_out[0, i])

# pool1_out: [1, 3, 12, 12]
input_feature = pool1_out[0]  # shape: [3, 12, 12]
weight = model.conv2.weight.data  # shape: [3, 3, 5, 5]
bias = model.conv2.bias.data  # shape: [3]

output_channel = 0
output_y = 0
output_x = 0

acc = 0
print(f"\n[ğŸ” conv2 ê³„ì‚° ìƒì„¸] ì±„ë„ {output_channel} / ìœ„ì¹˜ ({output_y},{output_x})")

for in_c in range(3):  # 3 input channels
    kernel = weight[output_channel, in_c]  # [5x5]
    patch = input_feature[in_c, output_y:output_y + 5, output_x:output_x + 5]  # [5x5]
    mul = patch * kernel  # element-wise ê³±
    sum_mul = mul.sum().item()

    print(f"\nğŸ§© ì…ë ¥ ì±„ë„ {in_c}ì˜ patch Ã— kernel:")
    print("ì…ë ¥ íŒ¨ì¹˜:")
    print(patch)
    print("ì»¤ë„:")
    print(kernel)
    print("ê³±:")
    print(mul)
    print(f"í•©ê³„: {sum_mul}")

    acc += sum_mul

# bias ë”í•¨
acc += bias[output_channel].item()
print(f"\nâœ… Bias({bias[output_channel].item()}) ë”í•œ ìµœì¢… ê²°ê³¼: {acc}")
print(f"â¡ï¸ ì‹¤ì œ conv2_out ê°’: {conv2_out[0, output_channel, output_y, output_x].item()}")

# âœ… ReLU2 ì ìš©
relu2_out = F.relu(conv2_out)
print("\nğŸ”¹ [ReLU2 ì¶œë ¥] (Conv2 â†’ ReLU)")
for i in range(relu2_out.shape[1]):
    print(f"ReLU2 ì±„ë„ {i} ê°’:")
    print(relu2_out[0, i])

# âœ… MaxPooling2 ì ìš©
pool2_out = F.max_pool2d(relu2_out, 2, 2)
print("\nğŸ”¹ [MaxPool2 ì¶œë ¥] shape:", pool2_out.shape)
for i in range(pool2_out.shape[1]):
    print(f"MaxPool2 ì±„ë„ {i} ê°’:")
    print(pool2_out[0, i])

# âœ… Flatten (ë²¡í„°í™”)
flatten_out = pool2_out.view(pool2_out.size(0), -1)
print("\nğŸ”¹ [Flatten ì¶œë ¥] shape:", flatten_out.shape)
print("Flatten ê°’:")
print(flatten_out[0])  # ë°°ì¹˜ í¬ê¸° 1ì´ë¯€ë¡œ [0]ë§Œ ì¶œë ¥

# âœ… FC1 ì—°ì‚° (Fully Connected Layer)
fc1_out = model.fc1(flatten_out)

# âœ… FC1 ì—°ì‚° ìˆ˜ë™ ê³„ì‚° ìƒì„¸ ì¶œë ¥
print("\n" + "=" * 80)
print("ğŸ” [FC1 ìˆ˜ë™ ê³„ì‚° ìƒì„¸ ì¶œë ¥]")
print("=" * 80)

fc1_weight = model.fc1.weight.data  # shape: [3, 48]
fc1_bias = model.fc1.bias.data      # shape: [3]
flatten_input = flatten_out[0]      # shape: [48]

for class_idx in range(3):  # ì¶œë ¥ í´ë˜ìŠ¤ 3ê°œ
    print(f"\nğŸ¯ í´ë˜ìŠ¤ {class_idx} ê³„ì‚°:")
    acc = 0
    contribs = []

    for i in range(flatten_input.shape[0]):
        input_val = flatten_input[i].item()
        weight_val = fc1_weight[class_idx][i].item()
        prod = input_val * weight_val
        acc += prod
        contribs.append((i, input_val, weight_val, prod))

    # ì¶œë ¥ ìƒì„¸
    for idx, inp, w, p in contribs:
        print(f"  ì…ë ¥[{idx:02d}] Ã— ê°€ì¤‘ì¹˜[{idx:02d}] = {inp:.1f} Ã— {w:.1f} = {p:.1f}")

    print(f"  ğŸ“Š ê°€ì¤‘ì¹˜ê³± í•©ê³„ (bias ì „): {acc:.1f}")
    print(f"  ğŸ bias: {fc1_bias[class_idx].item():.1f}")
    acc += fc1_bias[class_idx].item()
    print(f"  âœ… ìµœì¢… ê²°ê³¼: {acc:.1f}")
    print(f"  ğŸ” PyTorch ì¶œë ¥ ê²°ê³¼: {fc1_out[0][class_idx].item():.1f}")
    print(f"  ğŸ“‰ ì°¨ì´: {abs(acc - fc1_out[0][class_idx].item()):.6f}")

print("\nğŸ”¹ [FC1 ì¶œë ¥] (ìµœì¢… ì¶œë ¥ ë²¡í„° - í´ë˜ìŠ¤ 3ê°œ)")
print(fc1_out[0])  # [0]: ì²« ë²ˆì§¸ ë°°ì¹˜ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼
