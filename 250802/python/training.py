# # *****************************ÏÑ§Î™Ö********************************* #
# # a ~ eÎäî Î™®Îç∏ÏùÑ ÎßåÎì§Í≥† ÌïôÏäµÏãúÌÇ§Í≥† Î™®Îç∏ÏùÑ Ï†ÄÏû•ÌïòÎäî Í≥ºÏ†ï
# # a-1ÏùÄ EMNIST Ï†ÑÎ∂Ä, a-2Îäî (a,b,c Îßå) ÌõàÎ†®ÌïòÎäî ÏΩîÎìú. Î™®Îç∏ ÌïôÏäµ ÏãúÌÇ¨ Îïå Îëò Ï§ë ÌïòÎÇòÎäî Î∞òÎìúÏãú Ï£ºÏÑù!
# # d.Îäî Î™®Îç∏ÏùÑ ÌïôÏäµÏãúÌÇ¨ Îïå ÌïòÏù¥Ìçº ÌååÎùºÎØ∏ÌÑ∞ ÌäúÎãùÏùÑ ÏÑ§Ï†ïÌï¥ Ï§Ñ Ïàò ÏûàÏùå
# # f Î∂ÄÌÑ∞Îäî Ï†ÄÏû•Îêú Î™®Îç∏Ïùò weight, biasÎßå ÌôïÏù∏ÌïòÎäî Í≥ºÏ†ï 
# # ÎßåÏïΩ ÌïôÏäµÏùÑ Îã§ ÏãúÌÇ®Ï†ÅÏù¥ ÏûàÍ≥† weight, biasÎßå ÌôïÏù∏ÌïòÎ†§Î©¥ a~e Ï£ºÏÑùÏ≤òÎ¶¨ÌïòÍ≥† ÌïòÍ∏∞
# # ***************************************************************** #

import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, Subset
# datasets : MNIST Í∞ôÏùÄ Îç∞Ïù¥ÌÑ∞ ÏÖãÏùÑ ÏâΩÍ≤å Í∞ÄÏ†∏Ïò§Í∏∞ ÏúÑÌï®
# transforms : Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨Î•º ÏúÑÌïúÎèÑÍµ¨



from torch.utils.data import DataLoader
# DataLoader : Îç∞Ïù¥ÌÑ∞Î•º batch Îã®ÏúÑÎ°ú ÎÇòÎà†ÏÑú Ï≤òÎ¶¨(Î©îÎ™®Î¶¨ Ï†àÏïΩ + Îπ†Î¶Ñ)

from PIL import ImageOps
from torchvision.datasets import EMNIST
import torch
torch.set_printoptions(threshold=float('inf'), sci_mode=False, precision=6)


#transform ÏòµÏÖò
transform = transforms.Compose([
    transforms.Lambda(lambda img: ImageOps.invert(img)),  # ÏÉâ Î∞òÏ†Ñ
    transforms.Lambda(lambda img: ImageOps.mirror(img)),  # Ï¢åÏö∞ ÎåÄÏπ≠ Î≥µÏõê
    transforms.Lambda(lambda img: img.rotate(90, expand=True)),  # ÏãúÍ≥ÑÎ∞©Ìñ• 90ÎèÑ ÌöåÏ†Ñ
    transforms.ToTensor()
#transform ÏòµÏÖò
# MNISTÎäî Í∏∞Î≥∏Ï†ÅÏúº PIL Ïù¥ÎØ∏ÏßÄ(0~255) (Python Image Library)
# Ïù¥ÎØ∏ÏßÄ Ïó¥Í∏∞ (.jpg, .png, .bmp, .gif, .tiff, ...)
# ÌÅ¨Í∏∞ Ï°∞Ï†à (resize)
# ÏûòÎùºÎÇ¥Í∏∞ (crop)
# ÌöåÏ†Ñ, ÌùëÎ∞± Î≥ÄÌôò, ÌïÑÌÑ∞ Ï†ÅÏö©
# ÌîΩÏÖÄ Í∞í Ï†ëÍ∑º
# TOTensor()Î•º Ïì∞Î©¥ ->[0.0, 1.0]Î≤îÏúÑÏùò ÌÖêÏÑúÎ°ú Î≥ÄÌôò
])




# ************** a-1. EMNIST Ï†ÑÏ≤¥ ÌõàÎ†®/ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ÏÖã ************** #
# *************************************************************** #

# EMNIST Îç∞Ïù¥ÌÑ∞ÏÖã Î∂àÎü¨Ïò§Í∏∞ (Ïòà: 'letters')
train_dataset = EMNIST(root='./data', split='letters', train=True, download=True, transform=transform)
test_dataset = EMNIST(root='./data', split='letters', train=False, download=True, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

# *************************************************************** #
# *************************************************************** #
# #
# #





# # **************** a-2. A,B,CÎßå  ÌõàÎ†®/ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ÏÖã *************** #
# # *************************************************************** #
# target_labels = [1, 2, 3]
# def filter_dataset(dataset):
#     indices = [i for i, (_, label) in enumerate(dataset) if label in target_labels]
#     filtered = Subset(dataset, indices)
#     return filtered
#
# # ÏõêÎ≥∏ Ï†ÑÏ≤¥ EMNIST Îç∞Ïù¥ÌÑ∞ÏÖã
# full_train_dataset = EMNIST(root='./data', split='letters', train=True, download=True, transform=transform)
# full_test_dataset = EMNIST(root='./data', split='letters', train=False, download=True, transform=transform)
#
# # 'a', 'b', 'c'Îßå ÌïÑÌÑ∞ÎßÅ
# train_dataset = filter_dataset(full_train_dataset)
# test_dataset = filter_dataset(full_test_dataset)
#
# # SubsetÏùÄ ÎÇ¥Î∂ÄÏóê indexÎßå Îì§Í≥† ÏûàÏñ¥ÏÑú custom Dataset Í∞êÏã∏Ï§òÏïº Ìï®
# class ABCDataset(torch.utils.data.Dataset):
#     def __init__(self, subset):
#         self.subset = subset
#
#     def __len__(self):
#         return len(self.subset)
#
#     def __getitem__(self, idx):
#         img, label = self.subset[idx]
#         return img, torch.tensor(label, dtype=torch.long)
#
# train_dataset = ABCDataset(train_dataset)
# test_dataset = ABCDataset(test_dataset)
#
# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)
# # *************************************************************** #
# # *************************************************************** #








# ********************* b. CNN Î™®Îç∏ ÎßåÎì§Í∏∞ ************************ #
# *************************************************************** #

import torch.nn as nn
import torch.nn.functional as F


class CNN(nn.Module):
    def __init__(self, ch1, ch2):
        super(CNN, self).__init__()

        # pixel Îç∞Ïù¥ÌÑ∞ Ï∂îÍ∞Ä
        self.conv1 = nn.Conv2d(1, ch1, kernel_size=5, padding=0, bias=True)
        # Ìï©ÏÑ±Í≥± Î†àÏù¥Ïñ¥

        self.pool = nn.MaxPool2d(2, 2)  # 2x2 Max pooling
        # MaxPool2d(2, 2): 2x2 ÏµúÎåÄ ÌíÄÎßÅ ‚Üí ÌÅ¨Í∏∞Î•º Ï†àÎ∞òÏúºÎ°ú Ï§ÑÏûÑ

        self.conv2 = nn.Conv2d(ch1, ch2, kernel_size=5, padding=0, bias=True)

        self.fc1 = nn.Linear(ch2 * 4 * 4, 26, bias=True)  # ÏôÑÏ†ÑÏó∞Í≤∞,  # a,b,c Î∂ÑÎ•ò
        # self.fc2 = nn.Linear(32, 3)  # a,b,c Î∂ÑÎ•ò

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        # x = x.view(-1, 3 * 4 * 4)  # Flatten
        x = x.view(x.size(0), -1)
        ##soft maxÌïúÍ±∞
        x = self.fc1(x)

        return x
# forward: ÏûÖÎ†•Ïù¥ Î™®Îç∏ÏùÑ ÌÜµÍ≥ºÌï† ÎïåÏùò Ïó∞ÏÇ∞ Ï†ïÏùò
# ReLU: ÎπÑÏÑ†Ìòï ÌôúÏÑ±Ìôî Ìï®Ïàò ‚Üí Îî•Îü¨ÎãùÏóêÏÑú Îß§Ïö∞ Ï§ëÏöî
# view: ÌÖêÏÑúÎ•º ÌéºÏ≥êÏÑú FC Î†àÏù¥Ïñ¥Ïóê ÎÑ£Ïùå
# *************************************************************** #
# *************************************************************** #





# ******************* c.ÏÜêÏã§Ìï®ÏàòÏôÄ ÏòµÌã∞ÎßàÏù¥Ï†Ä Ï†ïÏùò ****************** #
# ************************************************************** #

import torch.optim as optim
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# device : Î™®Îç∏Í≥º Îç∞Ïù¥ÌÑ∞Î•º CPU, GPU Ïñ¥ÎîîÏóê Ïò¨Î¶¥ÏßÄ Ï†ïÌï®

# ************************************************************** #
# ************************************************************** #






#
# # ********************** d.Î™®Îç∏ ÌõàÎ†® Î£®ÌîÑ ************************ #
# # channel_configs => Ï≤´ Î≤àÏß∏ kernerl Ï±ÑÎÑê Ïàò, Îëê Î≤àÏß∏ kernel Ï±ÑÎÑê Ïàò
# # epoch_list => epoch Ï¥ù Î™áÎ≤à Ìï†Í±¥ÏßÄ
# # ex) epoch_list = [5,6,7] => channel_configs Í∞ÅÍ∞ÅÏóê ÎåÄÌïòÏó¨ epoch 5,6,7Î≤à ÌïôÏäµÏãúÌÇ§Í≤†Îã§
# # ************************************************************** #
# # ÌõàÎ†® Î£®ÌîÑ
# channel_configs = [
#     (3, 3),
#     # (8, 4),
#     # (4, 8),
#     # (8, 8),
#     # (8, 16),
#     # (16, 16),
# ]
# epochs_list = [5]
#
# for ch1, ch2 in channel_configs:
#     for ep in epochs_list:
#         print(f"\n‚ñ∂Ô∏è Config: conv1={ch1}, conv2={ch2}, epochs={ep}")
#         model = CNN(ch1, ch2).to(device)
#
#         criterion = nn.CrossEntropyLoss()
#         # ÏòàÏ∏° Ï†ïÍ∞ë Í∞ÑÏùò Ï∞®Ïù¥ Í≥ÑÏÇ∞ÌïòÎäî Ìï®Ïàò
#         optimizer = optim.Adam(model.parameters(), lr=0.001)
#         # ÏòµÌã∞ÎßàÏù¥Ï†ÄÎäî Î™®Îç∏Ïùò weightÎ•º ÏóÖÎç∞Ïù¥Ìä∏
#         optimizer = optim.Adam(model.parameters(), lr=0.001)
#
#         for epoch in range(ep):
#             model.train()
#             total_loss = 0
#             for images, labels in train_loader:
#                 images, labels = images.to(device), (labels - 1).to(device)
#                 outputs = model(images)
#                 loss = criterion(outputs, labels)
#                 optimizer.zero_grad()
#                 loss.backward()
#                 optimizer.step()
#                 total_loss += loss.item()
#             print(f"  Epoch [{epoch+1}/{ep}] Loss: {total_loss:.4f}")
# # *************************Ï†ïÌôïÎèÑ ÌèâÍ∞Ä**************************** #
# # ************************************************************** #
#         model.eval()
#         correct, total = 0, 0
#         with torch.no_grad():
#             for images, labels in test_loader:
#                 images, labels = images.to(device), (labels - 1).to(device)
#                 outputs = model(images)
#                 _, predicted = torch.max(outputs, 1)
#                 correct += (predicted == labels).sum().item()
#                 total += labels.size(0)
#         acc = 100 * correct / total
#         print(f"‚úÖ Accuracy: {acc:.2f}%")
#
#
#
#
#
#
# # ********************** e.Î™®Îç∏ Ï†ïÌôïÎèÑ ÌèâÍ∞Ä Î∞è Ï†ÄÏû• *********************** #
# # ********************************************************************* #
#         model.eval()
#         correct, total = 0, 0
#         with torch.no_grad():
#             for images, labels in test_loader:
#                 images, labels = images.to(device), (labels - 1).to(device)
#                 outputs = model(images)
#                 _, predicted = torch.max(outputs, 1)
#                 correct += (predicted == labels).sum().item()
#                 total += labels.size(0)
#         acc = 100 * correct / total
#         print(f"‚úÖ Accuracy: {acc:.2f}%")
#
#
#         # üîΩ Î™®Îç∏ Ï†ÄÏû•
#         filename = f"cnn_c{ch1}_{ch2}_ep{ep}.pth"
#         torch.save(model.state_dict(), filename)
#         print(f"üì¶ Model saved as: {filename}")
# # ************************************************************** #
# # ************************************************************** #





# # **************** f. ÌõàÎ†® Î™®Îç∏ weight, bias ÌôïÏù∏ **************** #
# # ************************************************************** #
#
# # ÎÇòÏ§ëÏóê ÌõàÎ†®Î™®Îç∏ weightÎßå ÌôïÏù∏ÌïòÍ≥† Ïã∂ÏùÑ Îïå

#ÏõêÌïòÎäî Î™®Îç∏ Ïù∏Îç±Ïã±ÏúºÎ°ú Ï∞æÍ∏∞
# ex) model.load_state_dict(torch.load("cnn_cX_X_epX.pth"))
# xÎ°ú ÎêòÏñ¥ÏûàÎäîÍ≥≥Ïóê ÏõêÌïòÎäî Ïà´Ïûê ÎÑ£Í∏∞ ( ex) ch1 = 3, ch2 = 3, ep =5 Ïù¥Î©¥ ÏïÑÎûòÏ≤òÎüº)
model = CNN(3, 3)
model.load_state_dict(torch.load("cnn_c3_3_ep5_a_z.pth"))
model.eval()

# Î™®Îç∏ conv1Ïùò weight
print("=== Conv1 Weights ===")
print(model.conv1.weight.shape)  # => torch.Size([16, 1, 3, 3])
print(model.conv1.weight)  # => Ïã§Ï†ú Í∞í Ï∂úÎ†•



print("=== Conv2 Weights ===")
print(model.conv2.weight.shape)  # => torch.Size([16, 1, 3, 3])
print(model.conv2.weight)  # => Ïã§Ï†ú Í∞í Ï∂úÎ†•

print("\n=== FC1 Weights ===")
print(model.fc1.weight.shape)  # ex) torch.Size([128, 1568])
print(model.fc1.weight)

print("\n=== bias ===")
print("conv1 bias:", model.conv1.bias.data)
print("conv2 bias:", model.conv2.bias.data)
print("fc1 bias:", model.fc1.bias.data)
# ************************************************************** #
# ************************************************************** #




# # **************** g. weight, bias memÌååÏùºÎ°ú Î≥ÄÌôò **************** #
# # ************************************************************** #
import os

print("\n================== bias, weight to mem file ==================")


weight_bias_path = r'C:\github\Braille_generator_FPGA\weight_bias_mem'

pixel_scale = 256
scale = 128  # Î≥¥ÌÜµ -1.0 ~ 1.0 ÏÇ¨Ïù¥Ïùò Í∞íÏù¥Î©¥ 128 Í≥±Ìï¥ÏÑú int8 ÏÇ¨Ïö©

# conv1.weight
weights = model.conv1.weight.data.clone().cpu()
print("\nconv1_weights.shape:", weights.shape)

# 1. Ï†ïÏàò Î≥ÄÌôò (Ïòà: 8ÎπÑÌä∏ Ï†ïÏàòÎ°ú Ïä§ÏºÄÏùºÎßÅ)
int_weights = (weights * scale).round().clamp(-scale, scale-1).to(torch.int8)
print("conv1_int_weights.shape:", int_weights.shape)
with open(os.path.join(weight_bias_path, "conv1_weight.mem"), "w") as f:
    for out_ch in range(int_weights.shape[0]):        # 16
        for in_ch in range(int_weights.shape[1]):     # 1
            for i in range(int_weights.shape[2]):     # 3
                for j in range(int_weights.shape[3]): # 3
                    val = int_weights[out_ch][in_ch][i][j].item()
                    hex_val = f"{(val & 0xFF):02x}"  # 2-digit hex (8bit signed)
                    f.write(f"0x{hex_val}\n")
print("conv1_weights_write_done")



# conv2.weight
weights = model.conv2.weight.data.clone().cpu()
print("\nconv2_weights.shape:", weights.shape)
int_weights = (weights * scale).round().clamp(-scale, scale-1).to(torch.int8)
print("conv2_int_weights.shape:", int_weights.shape)

with open(os.path.join(weight_bias_path, "conv2_weight.mem"), "w") as f:
    for out_ch in range(int_weights.shape[0]):
        for in_ch in range(int_weights.shape[1]):
            for i in range(int_weights.shape[2]):
                for j in range(int_weights.shape[3]):
                    val = int_weights[out_ch][in_ch][i][j].item()
                    hex_val = f"{(val & 0xFF):02x}"  # 2-digit hex (8bit signed)
                    f.write(f"0x{hex_val}\n")
print("conv2_weights_write_done")



# fc1.weight
weights = model.fc1.weight.data.clone().cpu()
print("\nfc1_weights.shape:", weights.shape)
int_weights = (weights * scale).round().clamp(-scale, scale-1).to(torch.int8)
print("fc1_int_weights.shape:", int_weights.shape)

with open(os.path.join(weight_bias_path, "fc1_weight.mem"), "w") as f:
    for out_ch in range(int_weights.shape[0]):
        for in_ch in range(int_weights.shape[1]):
            val = int_weights[out_ch][in_ch].item()
            hex_val = f"{(val & 0xFF):02x}"  # 2-digit hex (8bit signed)
            f.write(f"0x{hex_val}\n")
print("fc1_weights_write_done")



# conv1.bias
bias = model.conv1.bias.data.clone().cpu()
print("\nconv1_bias.shape:", bias.shape)
int_bias = (bias * scale).round().clamp(-scale, scale-1).to(torch.int8)
print("conv1_int_bias.shape:", int_bias.shape)
with open(os.path.join(weight_bias_path, "conv1_bias.mem"), "w") as f:
    for out_ch in range(int_bias.shape[0]):
        val = int_bias[out_ch].item()
        hex_val = f"{(val & 0xFFFF):04x}"  # 2-digit hex (8bit signed)
        f.write(f"0x{hex_val}\n")
print("conv1_bias_write_done")


# conv2.bias
bias = model.conv2.bias.data.clone().cpu()
print("\nconv2_bias.shape:", bias.shape)
int_bias = (bias * scale).round().clamp(-scale, scale-1).to(torch.int8)
print("conv2_int_bias.shape:", int_bias.shape)
with open(os.path.join(weight_bias_path, "conv2_bias.mem"), "w") as f:
    for out_ch in range(int_bias.shape[0]):
        val = int_bias[out_ch].item()
        hex_val = f"{(val & 0xFFFF):04x}"  # 2-digit hex (8bit signed)
        f.write(f"0x{hex_val}\n")
print("conv2_bias_write_done")


# fc1.bias
bias = model.conv2.bias.data.clone().cpu()
print("\nfc1_bias.shape:", bias.shape)
int_bias = (bias * scale).round().clamp(-scale, scale-1).to(torch.int8)
print("fc1_int_bias.shape:", int_bias.shape)
with open(os.path.join(weight_bias_path, "fc1_bias.mem"), "w") as f:
    for out_ch in range(int_bias.shape[0]):
        val = int_bias[out_ch].item()
        hex_val = f"{(val & 0xFFFF):04x}"  # 2-digit hex (8bit signed)
        f.write(f"0x{hex_val}\n")
print("fc1_bias_write_done")


